### **Project Overview:**

This project involves building and training **Autoencoders** and **Variational Autoencoders (VAE)** on the **Fashion-MNIST** dataset. The goal is to generate clothing-like images (e.g., shirts, pants, shoes, etc.) and visualize the effect of tweaking the latent variables in the learned latent space.

---

### **1. Autoencoders**

In this task, we train two **Autoencoder** models with different latent dimensions (16 and 48). The models are evaluated using reconstruction error and visualized with generated images.

#### **Steps:**

1. **Dataset Preparation**:
   - **Fashion-MNIST** dataset is loaded, which contains 60,000 training images and 10,000 test images of clothing items.
   - The images are transformed into tensors for model compatibility.

2. **Autoencoder Model Definition**:
   - **Encoder**: Compresses the input images into a lower-dimensional latent representation (latent vector).
   - **Decoder**: Reconstructs the images from the latent representation.
   
3. **Training**:
   - Two autoencoder models are trained with latent dimensions of **16** and **48**.
   - The **Mean Squared Error (MSE)** is used to calculate the reconstruction error.

4. **Results**:
   - **Reconstruction Errors** are reported for both training and test sets.
   - **8 original and reconstructed images** are visualized for both latent dimensions (16 and 48).

#### **Code Example:**

```python
# Define the Autoencoder model class
class Autoencoder(nn.Module):
    def __init__(self, latent_dim):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Flatten(),
            nn.Linear(28*28, 128),
            nn.ReLU(),
            nn.Linear(128, latent_dim)
        )
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 28*28),
            nn.Sigmoid(),
            nn.Unflatten(1, (1, 28, 28))
        )

    def forward(self, x):
        latent = self.encoder(x)
        reconstructed = self.decoder(latent)
        return reconstructed
```

5. **Results Evaluation**:
   - The **latent space interpolation** is performed by picking pairs of training samples, interpolating their latent space representations, and generating images from the interpolated points.
   - This allows visualization of smooth transitions between clothing types.

---

### **2. Variational Autoencoder (VAE)**

A **Variational Autoencoder (VAE)** is trained on the **Fashion-MNIST** dataset to generate new clothing-like images by learning a probability distribution in a **12-dimensional latent space**.

#### **Steps:**

1. **VAE Model Definition**:
   - The **encoder** maps the input image to a **mean** and **log variance** (which defines a distribution in the latent space).
   - The **decoder** reconstructs the image from a sampled latent variable.

2. **Training**:
   - The model is trained using the **reconstruction loss** (Binary Cross-Entropy) and the **KL divergence** between the learned distribution and the standard normal distribution.

3. **Image Generation**:
   - 50 images are generated by sampling latent variables from the learned distribution.
   - The diversity and quality of the generated samples are commented upon.

4. **Latent Variable Manipulation**:
   - The effect of modifying latent variables is visualized. For example, **shifting one dimension** of the latent vector alters the generated image, providing insight into the structure of the learned latent space.

#### **Code Example:**

```python
class VAE(nn.Module):
    def __init__(self, latent_dim=12):
        super(VAE, self).__init__()
        self.fc1 = nn.Linear(28*28, 400)
        self.fc2_mean = nn.Linear(400, latent_dim)
        self.fc2_log_var = nn.Linear(400, latent_dim)
        self.fc3 = nn.Linear(latent_dim, 400)
        self.fc4 = nn.Linear(400, 28*28)

    def encode(self, x):
        h1 = torch.relu(self.fc1(x))
        mean = self.fc2_mean(h1)
        log_var = self.fc2_log_var(h1)
        return mean, log_var

    def reparameterize(self, mean, log_var):
        std = torch.exp(0.5 * log_var)
        eps = torch.randn_like(std)
        return mean + std * eps

    def decode(self, z):
        h3 = torch.relu(self.fc3(z))
        return torch.sigmoid(self.fc4(h3))

    def forward(self, x):
        mean, log_var = self.encode(x.view(-1, 28*28))
        z = self.reparameterize(mean, log_var)
        recon_x = self.decode(z)
        return recon_x, mean, log_var
```

5. **Results Evaluation**:
   - **Generated Images**: After training, 50 new images are sampled from the learned latent space and displayed in a grid.
   - **Diversity and Quality**: The images should cover a wide variety of clothing types (shirts, pants, shoes) and should be recognizable as Fashion-MNIST items.
   - **Latent Variable Tweaks**: The effect of tweaking a single latent variable on the generated image is visualized, showing how changes in the latent space correspond to variations in the output image.

---

### **Final Results and Observations:**

1. **Autoencoders**:
   - The **latent dimension of 48** produces sharper and more detailed reconstructions compared to the **latent dimension of 16**.
   - Interpolating between pairs of training samples shows how the VAE smoothly transitions between clothing items, demonstrating the latent space's smoothness and structure.

2. **VAE**:
   - **Generated samples** show a good variety of clothing items, such as shirts, pants, and shoes.
   - **Quality**: The generated images are recognizable as Fashion-MNIST items with minor imperfections.
   - **Diversity**: The generated images are diverse, and tweaking latent variables clearly alters the output image, indicating a well-structured latent space.

---

### **Project Summary**:

- The **Autoencoder** model was used for **image reconstruction**, and **VAE** was used for **generating new images** from a learned distribution.
- The **latent space interpolation** and **latent variable tweaking** provided insights into how the VAE model learns the distribution of images and how different dimensions control various features of the clothing items.

---

### **Author**:
**Prince Verma**  
Roll Number: **SM24MTECH11003**

